## Capstone: Coursera Data Science
## Final Project
## Ignacio Ojea Quintana

# SHINY SERVER 

# Loading unigram, bigram, trigram and quadgram frequencies words matrix frequencies
# there were generated by Preprocessing.Rmd
ug <- readRDS("./data/unigram.RData")
bg <- readRDS("./data/bigram.RData")
tg <- readRDS("./data/trigram.RData")
qg <- readRDS("./data/quadgram.RData")
# Loading profanities for later clean up
naughtywords <- readLines('./data/bad-words.txt', encoding = 'UTF-8', skipNul = TRUE)
naughtywords <- iconv(naughtywords, "latin1", "ASCII", sub = "")

#####################################################

## Functions used in all prediction models

## Function to clean input so that we can later do the prediction
cleaninput <- function(input) {
        
        # Empty input
        if (input == "" | is.na(input)) {
                return("")
        }
        
        input <- tolower(input)
        
        # remove URL, email addresses, Twitter handles and hash tags
        input <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", input, ignore.case = FALSE, perl = TRUE)
        input <- gsub("\\S+[@]\\S+", "", input, ignore.case = FALSE, perl = TRUE)
        input <- gsub("@[^\\s]+", "", input, ignore.case = FALSE, perl = TRUE)
        input <- gsub("#[^\\s]+", "", input, ignore.case = FALSE, perl = TRUE)
        
        # remove ordinal numbers
        input <- gsub("[0-9](?:st|nd|rd|th)", "", input, ignore.case = FALSE, perl = TRUE)
        
        # remove profane words
        input <- removeWords(input, naughtywords)
        
        # remove punctuation
        input <- gsub("[^\\p{L}'\\s]+", "", input, ignore.case = FALSE, perl = TRUE)
        
        # remove punctuation
        input <- gsub("[.\\-!]", " ", input, ignore.case = FALSE, perl = TRUE)
        input <- gsub("'","",input)
        
        # trim leading and trailing whitespace
        input <- gsub("^\\s+|\\s+$", "", input)
        input <- stripWhitespace(input)
        
        if (input == "" | is.na(input)) {
                return("")
        }
        
        input <- unlist(strsplit(input, " "))
        
        return(input)
        
}

## A kind of Backoff underlying function

mostfrequentword <- ug[1,2]

nomatch <- paste("No matches were found. Most frequent word is:",mostfrequentword,sep=" ")
nocontent <- paste("Please suggest some content. Most frequent word is:",ug[1,2],sep=" ")


backoffprediction <- function(input, ngrams) {
        # Since we are always considering the tail of the input
        # I.E. make the input the last n words
        input <- tail(input, n=ngrams)
        
        # three (or more) entry words
        if (ngrams >= 3) {
                tokens <- subset(qg, qg$type1 == input[1] & qg$type2 == input[2] & qg$type3 == input[3])
                if (nrow(tokens) >= 1) {
                        return(tokens)}
                # backoff to trigram
                else {return(backoffprediction(input, ngrams - 1))}}
        
        # two entry words
        else if (ngrams == 2) {
                tokens <- subset(tg, tg$type1 == input[1] & tg$type2 == input[2])
                if (nrow(tokens) >= 1) {
                        return(tokens)}
                # backoff to bigram
                else {return(backoffprediction(input, ngrams - 1))}}
        
        # one entry word
        else if (ngrams == 1) {
                tokens <- subset(bg, bg$type1 == input[1])
                if (nrow(tokens) >= 1) {
                        return(tokens)}
                # backoff to most predicted word
                else {return(nomatch)}
                
                
        }
        # backoff to most predicted word
        else {return(nomatch)}
}

#########################

## Prediction with Simple Backoff
simpleBApredict <- function(input) {

        input <- cleaninput(input)
        
        if (input == "") {
                return(nocontent)
        } else if (length(input) == 1) {
                output <- backoffprediction(input, ngrams = 1)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                return(output[1,3])
        } else if (length(input) == 2) {
                output <- backoffprediction(input, ngrams = 2)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                if (ncol(output)==5){
                        return(output[1,3])}
                else if (ncol(output)==6){
                        return(output[1,4])}
        } else if (length(input) > 2) {
                output <- backoffprediction(input, ngrams = 3)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                if (ncol(output)==5){
                        return(output[1,3])}
                else if (ncol(output)==6){
                        return(output[1,4])}
                else if (ncol(output)==7){
                        return(output[1,5])}
        }
        
}


#############################

## Calculate Probabilities and attach them to the subset output
addprobs <- function(input){
         # the input here will be the output of the backoffprediction function,
         # namely a data frame with all of the alternative predictions 
         total <- sum(input$count)
         input$px <- (input$count/total)
         return(input)
 }

##############################

## Probabilistic Backoff Prediction

complexBApredict <- function(input){
        
        input <- cleaninput(input)

        if (input == "") {
                return(nocontent)} 
        else if (length(input) == 1) {
                output <- backoffprediction(input, ngrams = 1)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                word <- sample(output$type2,size=1,prob=output$px)
                return(word)} 
        else if (length(input) == 2) {
                output <- backoffprediction(input, ngrams = 2)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                if (ncol(output)==7){
                        word <- sample(output$type3,size=1,prob=output$px)
                        return(word)}
                else if (ncol(output)<7){
                        word <- sample(output$type2,size=1,prob=output$px)
                        return(word)}}
        else if (length(input) > 2) {
                output <- backoffprediction(input, ngrams = 3)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                if (ncol(output)>=8){
                        word <- sample(output$type4,size=1,prob=output$px)
                        return(word)
                }
                else if (ncol(output)==7){
                        word <- sample(output$type3,size=1,prob=output$px)
                        return(word)
                }
                else if (ncol(output)<7){
                        word <- sample(output$type2,size=1,prob=output$px)
                        return(word)
                }

        }
}

#################################################

## Linear Interpolation Model
# https://www.cs.cornell.edu/courses/cs4740/2012sp/lectures/smoothing+backoff-1-4pp.pdf


LinearIntpredict <- function(input){
        
        input <- cleaninput(input)
        
        if (input == "") {
                return(nocontent)}
        else if (length(input) == 1) {
                output <- backoffprediction(input, ngrams = 1)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                word <- sample(output$type2,size=1,prob=output$px)
                return(word)}
        else if (length(input) == 2) {
                output <- backoffprediction(input, ngrams = 2)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                if (ncol(output)==7){
                        word1 <- sample(output$type3,size=1,prob=output$px)
                        output2 <- backoffprediction(input, ngrams = 1)
                        output2 <- addprobs(output2)
                        word2 <- sample(output2$type2,size=1,prob=output2$px)                                
                        space <- c(word1,word2)
                        word <- sample(space,size=1,c(1/2,1/2),replace=TRUE)
                        return(word)}
                else if (ncol(output)<7){
                        word <- sample(output$type2,size=1,prob=output$px)
                        return(word)}}
        else if (length(input) > 2) {
                output <- backoffprediction(input, ngrams = 3)
                if (class(output)[1] == class(nomatch)){
                        return(nomatch)}
                output <- addprobs(output)
                if (ncol(output)>=8){
                        word1 <- sample(output$type4,size=1,prob=output$px)
                        output2 <- backoffprediction(input, ngrams = 2)
                        output2 <- addprobs(output2)
                        word2 <- sample(output2$type3,size=1,prob=output2$px)
                        output3 <- backoffprediction(input, ngrams = 1)
                        output3 <- addprobs(output3)
                        word3 <- sample(output3$type2,size=1,prob=output3$px)
                        space <- c(word1,word2,word3)
                        word <- sample(space,size=1,c(1/3,1/3,1/3),replace=TRUE)
                        return(word)
                }
                else if (ncol(output)==7){
                        word1 <- sample(output$type3,size=1,prob=output$px)
                        output2 <- backoffprediction(input, ngrams = 1)
                        output2 <- addprobs(output2)
                        word2 <- sample(output2$type2,size=1,prob=output2$px)
                        space <- c(word1,word2)
                        word <- sample(space,size=1,c(1/2,1/2),replace=TRUE)
                        return(word)
                }
                else if (ncol(output)<7){
                        word <- sample(output$type2,size=1,prob=output$px)
                        return(word)
                }
        }}


#################################################

## ShineServer code to call the function predictWord
shinyServer(function(input, output) {
        
        # original sentence
        output$userSentence1 <- renderText({input$userInput1});
        output$userSentence2 <- renderText({input$userInput2});
        output$userSentence3 <- renderText({input$userInput3});
        
        # reactive controls
        observe({
                output$prediction1 <- reactive({simpleBApredict(input$userInput1)})
                output$prediction2 <- reactive({complexBApredict(input$userInput2)})
                output$prediction3 <- reactive({LinearIntpredict(input$userInput3)})
        })
        
})

